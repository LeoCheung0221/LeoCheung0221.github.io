<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>【论文笔记】From Word Embeddings To Document Distances | ONE·PIECE</title><meta name="description" content="【论文笔记】From Word Embeddings To Document Distances"><meta name="keywords" content="算法,文档相似度,论文笔记,WMD"><meta name="author" content="Leo·Cheung,leocheung4ever@gmail.com"><meta name="copyright" content="Leo·Cheung"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="【论文笔记】From Word Embeddings To Document Distances"><meta name="twitter:description" content="【论文笔记】From Word Embeddings To Document Distances"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg"><meta property="og:type" content="article"><meta property="og:title" content="【论文笔记】From Word Embeddings To Document Distances"><meta property="og:url" content="http://tufusi.com/2019/11/24/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91From-Word-Embeddings-To-Document-Distances/"><meta property="og:site_name" content="ONE·PIECE"><meta property="og:description" content="【论文笔记】From Word Embeddings To Document Distances"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v4.7.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.15/dist/snackbar.min.css"><link rel="canonical" href="http://tufusi.com/2019/11/24/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91From-Word-Embeddings-To-Document-Distances/"><link rel="prev" title="【Kaggle专栏】Titanic入门" href="http://tufusi.com/2019/11/25/%E3%80%90Kaggle%E4%B8%93%E6%A0%8F%E3%80%91Titanic%E5%85%A5%E9%97%A8/"><link rel="next" title="机器学习篇-机器学习指南[译文]" href="http://tufusi.com/2019/11/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97-%E8%AF%91%E6%96%87/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"RG8HX7QXWX","apiKey":"a183cbbffa921b0dddc2872cfd1abd86","indexName":"WEBSITE001","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://tufusi.com/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: 'true',
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"}
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">ONE·PIECE</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/news/"><i class="fa-fw fa fa-newspaper-o"></i><span> AI头条</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-battery-half" aria-hidden="true"></i><span> 充电驿站</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/e-books/"><i class="fa-fw fa fa-book"></i><span> 小书屋</span></a></li><li><a class="site-page" href="/e-movies/"><i class="fa-fw fa fa-film"></i><span> 大影单</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="http://img.wdjimg.com/mms/icon/v1/9/9c/de366a247aeddb5809193003fa9c99c9_256_256.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">17</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">34</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/news/"><i class="fa-fw fa fa-newspaper-o"></i><span> AI头条</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-battery-half" aria-hidden="true"></i><span> 充电驿站</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/e-books/"><i class="fa-fw fa fa-book"></i><span> 小书屋</span></a></li><li><a class="site-page" href="/e-movies/"><i class="fa-fw fa fa-film"></i><span> 大影单</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#简介"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">简介</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#有关研究工作"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">有关研究工作</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Word2Vec-Embedding（词向量嵌入）"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">Word2Vec Embedding（词向量嵌入）</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Earth-Mover’s-Distance（推土机距离）"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">Earth Mover’s Distance（推土机距离）</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Word-Mover’s-Distance（词移距离）"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">Word Mover’s Distance（词移距离）</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#总结"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">总结</span></a></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#有关研究工作"><span class="toc-number">2.</span> <span class="toc-text">有关研究工作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Word2Vec-Embedding（词向量嵌入）"><span class="toc-number">2.1.</span> <span class="toc-text">Word2Vec Embedding（词向量嵌入）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Earth-Mover’s-Distance（推土机距离）"><span class="toc-number">2.2.</span> <span class="toc-text">Earth Mover’s Distance（推土机距离）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-Mover’s-Distance（词移距离）"><span class="toc-number">2.3.</span> <span class="toc-text">Word Mover’s Distance（词移距离）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">【论文笔记】From Word Embeddings To Document Distances</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-11-24<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-11-29</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon" aria-hidden="true"></i><span>字数总计: </span><span class="word-count">1.9k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon" aria-hidden="true"></i><span>阅读时长: 6 分钟</span><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true">       </i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><p>对于NLP领域来说，稍微拿一块知识点出来研究都是别有洞天，此篇是贪心学院布置的第一篇论文Lecture，于2015年由华盛顿大学发表，主要是为计算文本（语句）相似度提出的一种度量方法。在此之前，计算两个文档的相似度主要是通过词频，但这其实很难作为衡量依据的。</p>
<p>因此这篇论文的意义在于它提出这样一种思想：通过使用词向量（Word2Vec）表示词语，用WMD（Word Mover’s Distance）来衡量向量距离，以此计算文档相似度。</p>
<p>通过简单用例来阐述可能会更好，如下：</p>
<ul>
<li>A - “编程 使 我 快乐”</li>
<li>B - “唱歌 使 我 快乐”</li>
<li>C - “我 觉得 编程 有乐趣 “</li>
</ul>
<p>统计得到词袋向量：</p>
<ul>
<li>A - [“编程”：$\frac{1}{4}$，”使”：$\frac{1}{4}$，”我”：$\frac{1}{4}$，”快乐”：$\frac{1}{4}$，”唱歌：0，”觉得”：0，”有乐趣”：0]</li>
<li>B - [“编程”：0，”使”：$\frac{1}{4}$，”我”：$\frac{1}{4}$，”快乐”：$\frac{1}{4}$，”唱歌：$\frac{1}{4}$，”觉得”：0，”有乐趣”：0]</li>
<li>B - [“编程”：$\frac{1}{4}$，”使”：0，”我”：$\frac{1}{4}$，”快乐”：0，”唱歌：0，”觉得”：$\frac{1}{4}$，”有乐趣”：$\frac{1}{4}$]</li>
</ul>
<p>通过以上的特征向量，可以很明显看出第一句和第二句相似度很高，但是从我想要表达的语义来看，第一句和第三局似乎内容更匹配更有串联关系。再比如经典等式：king-man = queen-women，因此通过词频（IF-TDF）表示法是比较难表达语句中丰富的语义信息。这也正是这篇论文的意义所在，其核心思想在于突出词与词之间的距离特征映射关系。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文主要是提出一种基于词移动距离（Word Mover’s Distance， WMD）的文本相似度计算方法。它把大量的工作都用在了word2vec训练词向量（围绕基于词在句子中的总共出现概率训练词向量来展开的），WMD距离计算是针对某篇文章中的每一个词的，并在对比文档中找到一个词，使得该词“travel”到原文档中词的“cost”最小（即两个词向量最小距离），因而两篇文章相似度其实就是一篇文章中的所有词转移到另一篇文章中的词的”总代价“。这里得提一下EMD（下文有介绍 <a href="##Earth Mover's Distance（推土机距离）">点击跳转</a>），WMD和EMD两者的思路其实是一样的。这种衡量方法最直接的好处在于计算从头至尾都没有用到超参数，而且在paper中也论证了WMD的简单可效，在当时WMD算法甚至击败了其他7种主流文本相似度度量算法，具体可查看<a href="http://proceedings.mlr.press/v37/kusnerb15.pdf" target="_blank" rel="noopener">论文</a>Figure 3柱状图了解。</p>
<h1 id="有关研究工作"><a href="#有关研究工作" class="headerlink" title="有关研究工作"></a>有关研究工作</h1><h2 id="Word2Vec-Embedding（词向量嵌入）"><a href="#Word2Vec-Embedding（词向量嵌入）" class="headerlink" title="Word2Vec Embedding（词向量嵌入）"></a>Word2Vec Embedding（词向量嵌入）</h2><p><a href="http://wikipedia.moesalih.com/Word2vec" target="_blank" rel="noopener">Word2vec</a> 维基百科是这样解释的：它是一群用来产生词向量的相关模型。这些模型为浅两层的神经网络，用来训练以此重新构建符合语言学下的词文本。所以它也是一种词向量的表示模型，经过转换，可以把原先稀疏的特征转化为稠密的特征，而且语义相近的词之间的欧式距离也会比语义无关的词距离更大，这就相当于根据语义把意思相似的词聚合在很近的空间范围之内。<br>关于Word2Vec感觉还能再细分下去，后面抽时间再整理一下。</p>
<h2 id="Earth-Mover’s-Distance（推土机距离）"><a href="#Earth-Mover’s-Distance（推土机距离）" class="headerlink" title="Earth Mover’s Distance（推土机距离）"></a>Earth Mover’s Distance（推土机距离）</h2><p>EMD距离用来表示两个分布的相似程度，它是归一化的从一个分布变为另一个分布的最小代价，虽然其主要应用在图像处理和语音信号处理领域里，但是在NLP里似乎也深受其影响，因为这很符合文本对比的特点：两个文本里面包含的词语肯定不可能一致，所以也就肯定能够找到这样一个代价使得文本之间的相似性度量达到最大，这也正是下面要介绍的WMD算法。</p>
<h2 id="Word-Mover’s-Distance（词移距离）"><a href="#Word-Mover’s-Distance（词移距离）" class="headerlink" title="Word Mover’s Distance（词移距离）"></a>Word Mover’s Distance（词移距离）</h2><p>再看上面的用例，计算转移距离的时候，为了得到最小的距离，A中的”编程/我”，会全部转移到C中的”编程/我”（距离代价为0），而”快乐/有乐趣”以及”觉得/使”也是最接近的，也全部转移。因此，从本质上来说，在计算语句相似度时，WMD算法会计算文章中最相近的词之间的距离，但不会考虑整体，这大大增加的算法的健壮，不会因为文章整体的异同而表现出算法的不顽健。</p>
<p>先理解一下WMD算法：<br>1）有 词向量矩阵<script type="math/tex">\mathbf{X}\in \mathbf{R}^{d*n}</script>，其中n是数据集大小，d是词向量维度<br>2）某篇文章表示成归一化后的词袋向量为<script type="math/tex">\mathbf{b}\in \mathbf{R}^{n}</script><br>3）那么每一维度就是该词在文章出现的次数，很显然这个BOW是非常稀疏的，因为大量的词是不会出现在同一篇文章里的（TF-IDF，能出现大概率的只会是无语义词）<br>4）当两篇文章都用词袋向量<script type="math/tex">\mathbf{b}</script>表示后，如果语义相近，且用词也相近就可以知道向量的距离肯定也是相近的。但是如果两篇文章语义相近但是用词不同，那么这俩个向量的距离就会很散。<br>5) word2vec计算两篇文章中的两个词的距离向量，记为<script type="math/tex">\mathbf{c}(i,j)</script><br>6) 定义转移矩阵<script type="math/tex">\mathbf{T}\in \mathbf{R}^{n*n}</script>，其中：矩阵中的每一个值<script type="math/tex">T_{i,j}</script>代表单词i有多少权重要flow到单词j，我们只需保证，该词flow出的权重等于该单词在BOW中所有的权重即可，即<script type="math/tex">\sum_{j}^{}\mathbf{T}_{ij}=d_j</script>。<br>7) 只需找到累加求和距离最小权重分配比， 就可以求出最终两文本间的相似度。</p>
<p>最终数学表达公式为：</p>
<script type="math/tex; mode=display">min\sum_{i,j=1}^{n}\mathbf{T}_{ij} \mathbf{c}(i,j)</script><p>s.t:  <script type="math/tex">\sum_{j=1}^{n}\mathbf{T}_{ij}=d_i</script> &emsp;&emsp;  <script type="math/tex">\forall _i\in \{1,...,n\}</script> &emsp; <script type="math/tex">\cdots \cdots \cdots  (1)</script></p>
<p>&emsp;<script type="math/tex">\sum_{i=1}^{n}\mathbf{T}_{ij}=d'_j</script>  &emsp;&emsp; <script type="math/tex">\forall _j\in \{1,...,n\}</script></p>
<p>附上图<br>图一：<br><img alt="Figure 1" data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/GreedyAICDN@latest/paper/Figure1.jpg" class="lazyload"><br>图一说明单词移动距离。两篇文档中所有不间断的单词（粗体）都嵌入到另一个word2vec空间中</p>
<p>图二：<br><img alt="Figure 2" data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/GreedyAICDN@latest/paper/Figure%202.jpg" class="lazyload"><br>（上）WMD度量组件在查询语句<script type="math/tex">D_0</script>及语句<script type="math/tex">D_1</script>，<script type="math/tex">D_2</script>（两者有相等的词袋模型距离）间的展示。箭头表示两个单词之间的流动，并标有它们的距离贡献。<br>（下）两个语句<script type="math/tex">D_3</script>和<script type="math/tex">D_0</script>之间的流动情况展示，这种不匹配是由WMD将单词移动到了多个相似的单词导致的。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>到这里，简单描述了整篇论文的核心算法思想，当然还有很多研究工作需要进行，包括对WMD算法的优化之类，本文主要是为后续的文本相似度计算打下点基础，在熬了三周后参考各种文档，有关文本相似度计算总算是入门了，既然选择这一行，再难都会过去，就跟当初毕业走上Android开发这条路一样，学就对了。</p>
<p>这里可参考词移距离gensim官方<a href="https://github.com/RaRe-Technologies/gensim/blob/c971411c09773488dbdd899754537c0d1a9fce50/docs/notebooks/WMD_tutorial.ipynb" target="_blank" rel="noopener">Demo</a>，这是一款主题模型开源库。</p>
<p>最后附上论文链接：<a href="http://proceedings.mlr.press/v37/kusnerb15.pdf" target="_blank" rel="noopener">http://proceedings.mlr.press/v37/kusnerb15.pdf</a></p>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95/">算法    </a><a class="post-meta__tags" href="/tags/%E6%96%87%E6%A1%A3%E7%9B%B8%E4%BC%BC%E5%BA%A6/">文档相似度    </a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记    </a><a class="post-meta__tags" href="/tags/WMD/">WMD    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/img/alipay.jpg"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/11/25/%E3%80%90Kaggle%E4%B8%93%E6%A0%8F%E3%80%91Titanic%E5%85%A5%E9%97%A8/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>【Kaggle专栏】Titanic入门</span></div></a></div><div class="next-post pull_right"><a href="/2019/11/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97-%E8%AF%91%E6%96%87/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/img/page_diamond_paint.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>机器学习篇-机器学习指南[译文]</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/11/25/【Kaggle专栏】Titanic入门/" title="【Kaggle专栏】Titanic入门"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg"><div class="relatedPosts_title">【Kaggle专栏】Titanic入门</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="lv-container" data-id="city" data-uid="MTAyMC80NzU5OC8yNDA5OA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div></div><footer id="footer" style="background-image: url(https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2019 By Leo·Cheung</div><div class="footer_custom_text">Some of life, you have to go to the great challanges. - By Kobe Bryant</div><div class="icp"><a href="http://www.beian.miit.gov.cn/state/outPortal/loginPortal.action" target="_blank" rel="noopener"><img class="icp-icon" src="/img/icp.png"><span>浙ICP备19024714号</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script async src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.15/dist/snackbar.min.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/ClickShowText.js"></script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>