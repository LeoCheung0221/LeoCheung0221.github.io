<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>【Kaggle专栏】Titanic入门 | ONE·PIECE</title><meta name="description" content="【Kaggle专栏】Titanic入门"><meta name="keywords" content="Kaggle,数据竞赛,算法"><meta name="author" content="Leo·Cheung,leocheung4ever@gmail.com"><meta name="copyright" content="Leo·Cheung"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="【Kaggle专栏】Titanic入门"><meta name="twitter:description" content="【Kaggle专栏】Titanic入门"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg"><meta property="og:type" content="article"><meta property="og:title" content="【Kaggle专栏】Titanic入门"><meta property="og:url" content="http://tufusi.com/2019/11/25/%E3%80%90Kaggle%E4%B8%93%E6%A0%8F%E3%80%91Titanic%E5%85%A5%E9%97%A8/"><meta property="og:site_name" content="ONE·PIECE"><meta property="og:description" content="【Kaggle专栏】Titanic入门"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v4.7.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.15/dist/snackbar.min.css"><link rel="canonical" href="http://tufusi.com/2019/11/25/%E3%80%90Kaggle%E4%B8%93%E6%A0%8F%E3%80%91Titanic%E5%85%A5%E9%97%A8/"><link rel="prev" title="【机器学习模型】决策树学习（一）" href="http://tufusi.com/2019/11/30/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/"><link rel="next" title="【论文笔记】From Word Embeddings To Document Distances" href="http://tufusi.com/2019/11/24/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91From-Word-Embeddings-To-Document-Distances/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"RG8HX7QXWX","apiKey":"a183cbbffa921b0dddc2872cfd1abd86","indexName":"WEBSITE001","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://tufusi.com/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: 'true',
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"}
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">ONE·PIECE</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/news/"><i class="fa-fw fa fa-newspaper-o"></i><span> AI头条</span></a></div><div class="menus_item"><a class="site-page" href="/papers/"><i class="fa-fw fa fa-paper-plane-o"></i><span> 论文推荐</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-battery-half" aria-hidden="true"></i><span> 充电驿站</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/e-books/"><i class="fa-fw fa fa-book"></i><span> 小书屋</span></a></li><li><a class="site-page" href="/e-movies/"><i class="fa-fw fa fa-film"></i><span> 大影单</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="http://img.wdjimg.com/mms/icon/v1/9/9c/de366a247aeddb5809193003fa9c99c9_256_256.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">18</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">33</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/news/"><i class="fa-fw fa fa-newspaper-o"></i><span> AI头条</span></a></div><div class="menus_item"><a class="site-page" href="/papers/"><i class="fa-fw fa fa-paper-plane-o"></i><span> 论文推荐</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-battery-half" aria-hidden="true"></i><span> 充电驿站</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/e-books/"><i class="fa-fw fa fa-book"></i><span> 小书屋</span></a></li><li><a class="site-page" href="/e-movies/"><i class="fa-fw fa fa-film"></i><span> 大影单</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#比赛流程"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">比赛流程</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#背景介绍"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">背景介绍</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据集"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">数据集</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#导库-amp-加载"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">导库 &amp; 加载</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Data-Dictionary"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">Data Dictionary</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Exploratory-Data-Analysis"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text">Exploratory Data Analysis</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1、处理数据"><span class="toc_mobile_items-number">1.5.1.</span> <span class="toc_mobile_items-text">1、处理数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2、特征工程"><span class="toc_mobile_items-number">1.5.2.</span> <span class="toc_mobile_items-text">2、特征工程</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3、缺失数据处理（清理数据）"><span class="toc_mobile_items-number">1.5.3.</span> <span class="toc_mobile_items-text">3、缺失数据处理（清理数据）</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4、建模"><span class="toc_mobile_items-number">1.5.4.</span> <span class="toc_mobile_items-text">4、建模</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#总结"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">总结</span></a></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#比赛流程"><span class="toc-number">1.</span> <span class="toc-text">比赛流程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#背景介绍"><span class="toc-number">1.1.</span> <span class="toc-text">背景介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据集"><span class="toc-number">1.2.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#导库-amp-加载"><span class="toc-number">1.3.</span> <span class="toc-text">导库 &amp; 加载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-Dictionary"><span class="toc-number">1.4.</span> <span class="toc-text">Data Dictionary</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Exploratory-Data-Analysis"><span class="toc-number">1.5.</span> <span class="toc-text">Exploratory Data Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、处理数据"><span class="toc-number">1.5.1.</span> <span class="toc-text">1、处理数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、特征工程"><span class="toc-number">1.5.2.</span> <span class="toc-text">2、特征工程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、缺失数据处理（清理数据）"><span class="toc-number">1.5.3.</span> <span class="toc-text">3、缺失数据处理（清理数据）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4、建模"><span class="toc-number">1.5.4.</span> <span class="toc-text">4、建模</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-number">2.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">【Kaggle专栏】Titanic入门</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-11-25<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-12-02</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon" aria-hidden="true"></i><span>字数总计: </span><span class="word-count">3.8k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon" aria-hidden="true"></i><span>阅读时长: 15 分钟</span><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true">       </i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><p><a href="https://www.kaggle.com" target="_blank" rel="noopener">Kaggle</a>——作为一款以举办机器学习竞赛、编写和分享代码的平台，正在被越来越多的数据分析爱好者所青睐，这其中更是吸引了数以十万计数据科学家的关注。也正于此，才会被谷歌收入麾下。本人作为一名萌新，本着对机器学习的执著与热爱，在参考多篇文章之后，希望可以为同样喜爱Kaggle的盆友记录写下一点东西，再次感谢那些引路者，正是因为你们，国家在AI这条路上才能越走越远，才会越发强盛。</p>
<h1 id="比赛流程"><a href="#比赛流程" class="headerlink" title="比赛流程"></a>比赛流程</h1><ul>
<li>1、赛题背景了解（这会影响第四步）</li>
<li>2、数据集下载</li>
<li>3、分析数据 </li>
<li>4、数据处理与特征工程</li>
<li>5、模型评估与选择</li>
<li>6、结果预测提交</li>
<li>7、算法模型优化</li>
</ul>
<p>上述步骤，以Kaggle竞赛题《Titanic: Machine Learning from Disaster》为样例，预测泰坦尼克号乘客幸存来熟悉机器学习基础知识以及竞赛流程。具体每个步骤所涉及的操作官网均有介绍，相信也更有说服力，这里直接贴代码分析。</p>
<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>耳熟能详的『Jack and Rose』爱情故事延传至今，船长的一句『Lady  and kid first！』给原本悲怆黯然的故事增添了敬意，或许这对在当时惊恐万分的人们来说是末日，但时至今日，借助机器之力生成预测模型，是否可以做些预测，让更多的人存活下去，我们可以试试。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul>
<li><p>gender-submission.csv  待提交样例：该预测集只是假设女性乘客幸存下来  </p>
</li>
<li><p>test.csv   测试集：检测模型创建后的准确率</p>
</li>
<li><p>train.csv  训练集：用于训练生成模型</p>
</li>
</ul>
<h2 id="导库-amp-加载"><a href="#导库-amp-加载" class="headerlink" title="导库 &amp; 加载"></a>导库 &amp; 加载</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd #数据分析库</span><br><span class="line">import numpy as np #科学计算库</span><br><span class="line">from pandas import Series, DataFrame</span><br><span class="line"></span><br><span class="line">data_train = pd.read_csv(&quot;train.csv&quot;)</span><br><span class="line">data_train.columns</span><br></pre></td></tr></table></figure>
<p>有上，打印出训练集中的各特征字段名称</p>
<h2 id="Data-Dictionary"><a href="#Data-Dictionary" class="headerlink" title="Data Dictionary"></a>Data Dictionary</h2><pre><code>PassengerId  ==＞ 乘客ID
Survived ==＞ 乘客是否幸存 0=罹难，1=幸存
Pclass ==＞ 票类 1=一等舱，2=二等舱，3=三等舱
Name  ==＞ 乘客姓名
Sex  ==＞ 乘客性别
Age  ==＞ 乘客年龄
SibSp  ==＞ 兄弟姐妹/配偶数量
Parch  ==＞ 双亲/子女数量
Ticket  ==＞ 票号信息
Fare  ==＞ 船运票价
Cabin  ==＞ 客舱号
Embarked  ==＞ 出发港口
</code></pre><p>罗列出字典内字段之后，我们需要通过理性思维来筛选出影响乘客幸存的因素再加上船长的『Lady  and kid first！』，甚至我们筛选条件可以再宽松一点，老人是否也可以提前乘上救生艇，这个后面再定，所以稍加思考可知</p>
<p>影响因素（暂定）包括：Sex、Pclass、Age</p>
<h2 id="Exploratory-Data-Analysis"><a href="#Exploratory-Data-Analysis" class="headerlink" title="Exploratory Data Analysis"></a>Exploratory Data Analysis</h2><h3 id="1、处理数据"><a href="#1、处理数据" class="headerlink" title="1、处理数据"></a>1、处理数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data_train.info()</span><br></pre></td></tr></table></figure>
<p>打印得到：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</span><br><span class="line">RangeIndex: 891 entries, 0 to 890</span><br><span class="line">Data columns (total 12 columns):</span><br><span class="line">PassengerId    891 non-null int64</span><br><span class="line">Survived       891 non-null int64</span><br><span class="line">Pclass         891 non-null int64</span><br><span class="line">Name           891 non-null object</span><br><span class="line">Sex            891 non-null object</span><br><span class="line">Age            714 non-null float64</span><br><span class="line">SibSp          891 non-null int64</span><br><span class="line">Parch          891 non-null int64</span><br><span class="line">Ticket         891 non-null object</span><br><span class="line">Fare           891 non-null float64</span><br><span class="line">Cabin          204 non-null object</span><br><span class="line">Embarked       889 non-null object</span><br><span class="line">dtypes: float64(2), int64(5), object(5)</span><br><span class="line">memory usage: 83.6+ KB</span><br></pre></td></tr></table></figure>
<p>可知：数据集包含891条数据，其中年龄Age有177条缺失，客舱号及出发港口均有不同程度的记录值缺失，这样看还不是很明确，换一下api查看，关于Pandas的DataFrame相关函数，可以参考另一篇文章<a href="http://tufusi.com/2019/11/17/Pandas%E5%BA%93%E4%B9%8BDataFrame/">传送门</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data_train.describe()</span><br></pre></td></tr></table></figure><br>打印如下</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">PassengerId</th>
<th style="text-align:center">Survived</th>
<th style="text-align:center">Pclass</th>
<th style="text-align:center">Age</th>
<th style="text-align:center">SibSp</th>
<th style="text-align:center">Parch</th>
<th style="text-align:center">Fare</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">count</td>
<td style="text-align:center">891.000000</td>
<td style="text-align:center">891.000000</td>
<td style="text-align:center">891.000000</td>
<td style="text-align:center">714.000000</td>
<td style="text-align:center">891.000000</td>
<td style="text-align:center">891.000000</td>
<td style="text-align:center">891.000000</td>
</tr>
<tr>
<td style="text-align:center">mean</td>
<td style="text-align:center">446.000000</td>
<td style="text-align:center">0.383838</td>
<td style="text-align:center">2.308642</td>
<td style="text-align:center">29.699118</td>
<td style="text-align:center">0.523008</td>
<td style="text-align:center">0.381594</td>
<td style="text-align:center">32.204208</td>
</tr>
<tr>
<td style="text-align:center">std</td>
<td style="text-align:center">257.353842</td>
<td style="text-align:center">0.486592</td>
<td style="text-align:center">0.836071</td>
<td style="text-align:center">14.526497</td>
<td style="text-align:center">1.102743</td>
<td style="text-align:center">0.806057</td>
<td style="text-align:center">49.693429</td>
</tr>
<tr>
<td style="text-align:center">min</td>
<td style="text-align:center">1.000000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">1.000000</td>
<td style="text-align:center">0.420000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">0.000000</td>
</tr>
<tr>
<td style="text-align:center">25%</td>
<td style="text-align:center">223.500000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">2.000000</td>
<td style="text-align:center">NaN</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">7.910400</td>
</tr>
<tr>
<td style="text-align:center">50%</td>
<td style="text-align:center">446.000000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">3.000000</td>
<td style="text-align:center">NaN</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">14.454200</td>
</tr>
<tr>
<td style="text-align:center">75%</td>
<td style="text-align:center">668.500000</td>
<td style="text-align:center">1.000000</td>
<td style="text-align:center">3.000000</td>
<td style="text-align:center">NaN</td>
<td style="text-align:center">1.000000</td>
<td style="text-align:center">0.000000</td>
<td style="text-align:center">31.000000</td>
</tr>
<tr>
<td style="text-align:center">max</td>
<td style="text-align:center">891.000000</td>
<td style="text-align:center">1.000000</td>
<td style="text-align:center">3.000000</td>
<td style="text-align:center">80.000000</td>
<td style="text-align:center">8.000000</td>
<td style="text-align:center">6.000000</td>
<td style="text-align:center">512.329200</td>
</tr>
</tbody>
</table>
</div>
<p>以上表格才稍微能看：<br>mean（平均数）得知Survived（存活）率约为38%；<br>Pclass=一等舱数＜Pclass=二/三等舱数；<br>乘客平均年龄为29岁，最大是80岁<br>等等…</p>
<h3 id="2、特征工程"><a href="#2、特征工程" class="headerlink" title="2、特征工程"></a>2、特征工程</h3><p>接着我们用点手段看最直观的图，使用绘图库Matplotlib</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">figure = plt.figure() #调用Figure对象</span><br><span class="line">figure.set(alpha = 1) #设置色值透明度</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3,5),(0,0),colspan=1) #使用子图</span><br><span class="line">data_train.Survived.value_counts().plot(kind=&apos;bar&apos;) #绘制柱状图</span><br><span class="line">plt.title(u&quot;获救情况『1为幸存』&quot;)</span><br><span class="line">plt.ylabel(u&quot;人数&quot;)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3,5),(0,2),colspan=1)</span><br><span class="line">data_train.Pclass.value_counts().plot(kind=&apos;bar&apos;)</span><br><span class="line">plt.title(u&quot;程票类型&quot;)</span><br><span class="line">plt.ylabel(u&quot;人数&quot;)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3,5),(0,4),colspan=1)</span><br><span class="line">plt.scatter(data_train.Survived, data_train.Age) #绘制散点图</span><br><span class="line">plt.grid(b=True, which=&apos;major&apos;, axis=&apos;y&apos;) #网格线绘制</span><br><span class="line">plt.title(u&quot;各年龄层幸存情况『1为幸存』&quot;)</span><br><span class="line">plt.ylabel(u&quot;年龄&quot;)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3,5),(2,0),colspan=2)</span><br><span class="line">data_train.Age[data_train.Pclass==1].plot(kind=&apos;kde&apos;) #绘制曲线图</span><br><span class="line">data_train.Age[data_train.Pclass==2].plot(kind=&apos;kde&apos;)</span><br><span class="line">data_train.Age[data_train.Pclass==3].plot(kind=&apos;kde&apos;)</span><br><span class="line">plt.legend((u&quot;一等舱&quot;, u&quot;二等舱&quot;, u&quot;三等舱&quot;), loc=&apos;best&apos;)</span><br><span class="line">plt.title(u&quot;各舱乘客年龄分布&quot;)</span><br><span class="line">plt.xlabel(u&quot;年龄&quot;)</span><br><span class="line">plt.ylabel(u&quot;占比&quot;)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((3,5),(2,4))</span><br><span class="line">data_train.Embarked.value_counts().plot(kind=&apos;bar&apos;)</span><br><span class="line">plt.title(u&quot;各出港口登船情况&quot;)</span><br><span class="line">plt.ylabel(u&quot;人数&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>运行得到绘图<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot1.png" class="lazyload"></p>
<p>注：以上是合成一张大网格罗列出的绘图，代码运行观看每一张更为直观<br>从上图种种可看出：</p>
<ul>
<li><p>大致有300多人获救</p>
</li>
<li><p>有一半以上购买三等舱 </p>
</li>
<li><p>各年龄层获救/罹难均有，分布较广</p>
</li>
<li><p>三等舱和二等舱总体趋势相似，并且年龄层占比最多的是在20、30岁左右，一等舱最多是40岁左右乘客</p>
</li>
<li><p>出港口人数以S（英国南安普敦（Southampton））最多，其次是C（法国 瑟堡-奥克特维尔（Cherbourg-Octeville）），最后是Q（爱尔兰 昆士敦（Queenstown）），不难理解，人数越多越有可能是出发港口，其他均是途径。</p>
</li>
</ul>
<p>现在我们有一些疑问了：</p>
<pre><code>① 这三百多人获救与购买不同等级舱有无关系？
② 年龄和性别对获救的影响大吗？（毕竟船长发过话）
③ 出港口的不同是不是也会影响乘客获救？
</code></pre><p>下面验证上面三个问题<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Survived_No = data_train.Pclass[data_train.Survived == 0].value_counts()</span><br><span class="line">Survived_Yes = data_train.Pclass[data_train.Survived == 1].value_counts()</span><br><span class="line">df = pd.DataFrame(&#123;u&quot;获救&quot;: Survived_Yes, u&quot;未获救&quot;: Survived_No&#125;)</span><br><span class="line">df.plot(kind=&apos;bar&apos;, stacked=True)</span><br><span class="line">plt.title(u&quot;各等级舱获救情况&quot;)</span><br><span class="line">plt.xlabel(u&quot;舱级&quot;)</span><br><span class="line">plt.ylabel(u&quot;人数&quot;)</span><br><span class="line">plt.show</span><br></pre></td></tr></table></figure><br>运行得到绘图<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot2.png" class="lazyload"><br>你看可以很明显的看出舱级越高幸存概率越大，这是决定因素之一</p>
<p>在看第二个问题<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Survived_m = data_train.Survived[data_train.Sex == &apos;male&apos;].value_counts()</span><br><span class="line">Survived_f = data_train.Survived[data_train.Sex == &apos;female&apos;].value_counts()</span><br><span class="line">df = pd.DataFrame(&#123;u&quot;男性&quot;: Survived_m, u&quot;女性&quot;: Survived_f&#125;)</span><br><span class="line">df.plot(kind=&apos;bar&apos;, stacked=True)</span><br><span class="line">plt.title(u&quot;各性别获救情况&quot;)</span><br><span class="line">plt.xlabel(u&quot;性别&quot;)</span><br><span class="line">plt.ylabel(u&quot;人数&quot;)</span><br><span class="line">plt.show</span><br></pre></td></tr></table></figure><br>运行<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot3.png" class="lazyload"><br>果然女性乘客获救比例比男性大很多，性别无疑也是作为模型中的重要的特征之一<br>同样年龄（取分割线为30岁，平均岁数）也可以尝试一下，并没有发现什么，但是随着分割的岁数越来越大，可以发现遇难的概率也是越来越大的，这也很符合常识，年迈的虽然会优先对待，但在那种恶劣处境下，毕竟求生本领还是很弱的。</p>
<p>看最后一个问题<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Survived_No = data_train.Embarked[data_train.Survived == 0].value_counts()</span><br><span class="line">Survived_Yes = data_train.Embarked[data_train.Survived == 1].value_counts()</span><br><span class="line">df = pd.DataFrame(&#123;u&quot;获救&quot;: Survived_Yes, u&quot;未获救&quot;: Survived_No&#125;)</span><br><span class="line">df.plot(kind=&apos;bar&apos;, stacked=True)</span><br><span class="line">plt.title(u&quot;各出港口乘客获救情况&quot;)</span><br><span class="line">plt.xlabel(u&quot;出港口&quot;)</span><br><span class="line">plt.ylabel(u&quot;人数&quot;)</span><br><span class="line">plt.show</span><br></pre></td></tr></table></figure><br>运行<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot4.png" class="lazyload"><br>不怎么看的出来， 如果要解释从出发港口出发的乘客获救的几率大一点似乎也没多大说服力。暂时不管</p>
<p>既然这样，那条件继续细分</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">plt.title(&quot;各等级舱男女获救情况&quot;)</span><br><span class="line"></span><br><span class="line">plot1 = fig.add_subplot(141) #表示1*4网格 第一子图</span><br><span class="line">data_train.Survived[data_train.Sex==&apos;male&apos;][data_train.Pclass !=3].value_counts().plot(kind=&apos;bar&apos;, label=&quot;male highlevel&quot;, color=&apos;#FEB838&apos;)</span><br><span class="line">plot1.set_xticklabels([u&quot;获救&quot;, u&quot;未获救&quot;], rotation = 0)</span><br><span class="line">plot1.legend([u&quot;男性/高等舱&quot;], loc=&apos;best&apos;)</span><br><span class="line"></span><br><span class="line">plot2 = fig.add_subplot(142, sharey = plot1) </span><br><span class="line">data_train.Survived[data_train.Sex==&apos;male&apos;][data_train.Pclass ==3].value_counts().plot(kind=&apos;bar&apos;, label=&quot;male lowlevel&quot;, color=&apos;#fcce0b&apos;)</span><br><span class="line">plot2.set_xticklabels([u&quot;获救&quot;, u&quot;未获救&quot;], rotation = 0)</span><br><span class="line">plot2.legend([u&quot;男性/低等舱&quot;], loc=&apos;best&apos;)</span><br><span class="line"></span><br><span class="line">plot3 = fig.add_subplot(143, sharey = plot1) </span><br><span class="line">data_train.Survived[data_train.Sex==&apos;female&apos;][data_train.Pclass !=3].value_counts().plot(kind=&apos;bar&apos;, label=&quot;male lowlevel&quot;, color=&apos;#BA6564&apos;)</span><br><span class="line">plot3.set_xticklabels([u&quot;获救&quot;, u&quot;未获救&quot;], rotation = 0)</span><br><span class="line">plot3.legend([u&quot;女性/高等舱&quot;], loc=&apos;best&apos;)</span><br><span class="line"></span><br><span class="line">plot4 = fig.add_subplot(144, sharey = plot1) </span><br><span class="line">data_train.Survived[data_train.Sex==&apos;female&apos;][data_train.Pclass ==3].value_counts().plot(kind=&apos;bar&apos;, label=&quot;male lowlevel&quot;, color=&apos;#ff6d6d&apos;)</span><br><span class="line">plot4.set_xticklabels([u&quot;获救&quot;, u&quot;未获救&quot;], rotation = 0)</span><br><span class="line">plot4.legend([u&quot;女性/低等舱&quot;], loc=&apos;best&apos;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>运行如下<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot5.png" class="lazyload"><br>继续<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f = data_train.groupby([&apos;SibSp&apos;, &apos;Survived&apos;])</span><br><span class="line">df = pd.DataFrame(f[&apos;PassengerId&apos;].count())</span><br><span class="line">df</span><br></pre></td></tr></table></figure><br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot6.png" class="lazyload"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f = data_train.groupby([&apos;Parch&apos;, &apos;Survived&apos;])</span><br><span class="line">df = pd.DataFrame(f[&apos;PassengerId&apos;].count())</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot7.png" class="lazyload"></p>
<p>还是看不出必然关系，那就先清洗一下数据，对缺失值做些处理，先从Cabin、Age缺失最严重却又是重要特征入手</p>
<h3 id="3、缺失数据处理（清理数据）"><a href="#3、缺失数据处理（清理数据）" class="headerlink" title="3、缺失数据处理（清理数据）"></a>3、缺失数据处理（清理数据）</h3><p><strong>通常遇到缺失值，最常见的处理方式有这些</strong></p>
<ul>
<li><p>1.如果缺失的样本字段值占比很多，一般都需要舍去，以防形成噪声影响结果</p>
</li>
<li><p>2.如果缺失样本占比适中，并且该属性是非连续性的特征属性，即分类属性的话，可引入NaN作为新类别特征</p>
</li>
<li><p>3.如果缺失样本占比适中，并且该属性是连续性的特征属性，可以考虑步长step，并将其离散化分布</p>
</li>
<li><p>4.如果缺失样本占比极少，可考虑手动加入拟合数据</p>
</li>
</ul>
<p>可以尝试<a href="https://scikit-learn.org/stable/modules/ensemble.html#forest" target="_blank" rel="noopener">随机森林</a>，一种集成学习模型，训练多个决策树，考虑多个结果做预测，这里使用<a href="https://scikit-learn.org/stable" target="_blank" rel="noopener">sklearn</a>库中的随机森林：</p>
<p><strong>它的随机性体现在</strong></p>
<ul>
<li><p>从原来的训练数据集随机（带放回样本）取一个子级作为森林中某个决策树的训练数据集</p>
</li>
<li><p>每一次选择分叉的特征时，限定为在随机选择的特征的子级中寻找一个特征 </p>
</li>
</ul>
<p><strong>它的优势体现在</strong></p>
<ul>
<li><p>消除决策树容易过拟合的缺点</p>
</li>
<li><p>减小预测的方差：预测值不会因为训练数据小变化而发生剧烈变化</p>
</li>
</ul>
<p>这里用scikit-learn 的Random-forest拟合缺失的年龄数据</p>
<p><strong>拟合缺失数据</strong><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line">data_train = pd.read_csv(&quot;train.csv&quot;)</span><br><span class="line">def fill_missing_age(df):</span><br><span class="line">    # 新建一个随机森林回归对象，并把已确定的特征值存入</span><br><span class="line">    df_age = df[[&apos;Age&apos;,&apos;Fare&apos;,&apos;Parch&apos;,&apos;SibSp&apos;,&apos;Pclass&apos;]]</span><br><span class="line">    </span><br><span class="line">    # 分成年龄缺失和不缺失两部分</span><br><span class="line">    age_known = df_age[df_age.Age.notnull()].values</span><br><span class="line">    age_unknown = df_age[df_age.Age.isnull()].values</span><br><span class="line">    </span><br><span class="line">    y = age_known[:, 0] #已知年龄区的所有年龄值</span><br><span class="line">    X = age_known[:, 1:] #已知年龄区的所有特征属性值</span><br><span class="line"></span><br><span class="line">    # 解释构造函数各参数</span><br><span class="line">    # random_state：此参数让结果容易复现。特定的随机状态值将会产生相同的结果。</span><br><span class="line">    # n_estimators：想建立的子树数量（前提是在利用最大投票数或平均值预测之前）</span><br><span class="line">    # n_jobs：告诉引擎可以有多少处理器可以使用（-1代表无限制，1代表只能使用一个处理器）</span><br><span class="line">    rfr= RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)</span><br><span class="line">    rfr.fit(X, y) # 训练到回归模型中</span><br><span class="line">    </span><br><span class="line">    # 进行结果预测</span><br><span class="line">    predict_age=rfr.predict(age_unknown[:, 1::])</span><br><span class="line">    # 预测值填充缺失数据</span><br><span class="line">    df.loc[(df.Age.isnull()),&apos;Age&apos;] = predict_age</span><br><span class="line">    </span><br><span class="line">    return df, rfr</span><br><span class="line"></span><br><span class="line">def fill_Cabin_type(df):</span><br><span class="line">    df.loc[(df.Cabin.notnull()), &apos;Cabin&apos;] = &quot;Yes&quot;</span><br><span class="line">    df.loc[(df.Cabin.isnull()), &apos;Cabin&apos;] = &quot;No&quot;</span><br><span class="line">    return df</span><br><span class="line"></span><br><span class="line">data_train, rfr = fill_missing_age(data_train)</span><br><span class="line">data_train = fill_Cabin_type(data_train)</span><br><span class="line">data_train</span><br></pre></td></tr></table></figure><br>运行得到如下（只截取部分）<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot8.png" class="lazyload"></p>
<p><strong>独热编码</strong><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dummies_Sex = pd.get_dummies(data_train[&apos;Sex&apos;], prefix=&apos;Sex&apos;)</span><br><span class="line">dummies_Cabin = pd.get_dummies(data_train[&apos;Cabin&apos;], prefix=&apos;Cabin&apos;)</span><br><span class="line">dummies_Pclass = pd.get_dummies(data_train[&apos;Pclass&apos;], prefix=&apos;Pclass&apos;)</span><br><span class="line">dummies_Embarked = pd.get_dummies(data_train[&apos;Embarked&apos;], prefix=&apos;Embarked&apos;)</span><br><span class="line"></span><br><span class="line">df = pd.concat([data_train, dummies_Sex, dummies_Cabin, dummies_Pclass, dummies_Embarked], axis=1)</span><br><span class="line">df.drop([&apos;Pclass&apos;, &apos;Name&apos;, &apos;Sex&apos;, &apos;Ticket&apos;, &apos;Cabin&apos;, &apos;Embarked&apos;], axis=1, inplace=True)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><br>得到<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot9.png" class="lazyload"></p>
<p><strong>对幅度过大特征属性值进行归一化  加速逻辑回归收敛</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sklearn.preprocessing as preprocessing</span><br><span class="line">scaler = preprocessing.StandardScaler()</span><br><span class="line"></span><br><span class="line">age_scale = scaler.fit(df[&apos;Age&apos;].values.reshape(-1,1))</span><br><span class="line">df[&apos;Age_scaled&apos;] = scaler.fit_transform(df[&apos;Age&apos;].values.reshape(-1,1), age_scale)</span><br><span class="line">fare_scale = scaler.fit(df[&apos;Fare&apos;].values.reshape(-1,1))</span><br><span class="line">df[&apos;Fare_scaled&apos;] = scaler.fit_transform(df[&apos;Fare&apos;].values.reshape(-1,1), fare_scale)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p>得到<br><img alt data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/blog/kaggle/kaggle_titanic_plot10.png" class="lazyload"></p>
<h3 id="4、建模"><a href="#4、建模" class="headerlink" title="4、建模"></a>4、建模</h3><p><strong>取出特征字段 模型建模</strong><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from sklearn import linear_model</span><br><span class="line"></span><br><span class="line">train_df = df.filter(regex=&apos;Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*&apos;)</span><br><span class="line">train_np = train_df.values</span><br><span class="line"></span><br><span class="line">y = train_np[:, 0]</span><br><span class="line">X = train_np[:, 1:]</span><br><span class="line"></span><br><span class="line"># 逻辑回归构造参数解析</span><br><span class="line"># C：正则化系数λ的倒数，通常默认为1</span><br><span class="line"># penalty：正则化选择惩罚项参数 可选择“l1”和“l2”正则，默认“l2” 主要为解决过拟合问题</span><br><span class="line"># penalty参数的选择会影响我们损失函数优化算法的选择。即参数solver的选择，</span><br><span class="line"># 如果是L2正则化，那么4种可选的算法&#123;‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’&#125;都可以选择。</span><br><span class="line"># 但是如果penalty是L1正则化的话，就只能选择‘liblinear’了。</span><br><span class="line"># 这是因为L1正则化的损失函数不是连续可导的，</span><br><span class="line"># 而&#123;‘newton-cg’, ‘lbfgs’,‘sag’&#125;这三种优化算法时都需要损失函数的一阶或者二阶连续导数。而‘liblinear’并没有这个依赖。</span><br><span class="line">lr_clf = linear_model.LogisticRegression(C=1.0, penalty=&apos;l1&apos;, solver=&apos;liblinear&apos;, tol=1e-6)</span><br><span class="line">lr_clf.fit(X, y)</span><br><span class="line"></span><br><span class="line">lr_clf</span><br></pre></td></tr></table></figure></p>
<p>最简版baseline</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data_test = pd.read_csv(&quot;test.csv&quot;)</span><br><span class="line">data_test.loc[ (data_test.Fare.isnull()), &apos;Fare&apos; ] = 0</span><br><span class="line"></span><br><span class="line"># 接着我们对test_data做和train_data中一致的特征变换</span><br><span class="line"># 首先用同样的RandomForestRegressor模型填上丢失的年龄</span><br><span class="line">tmp_df = data_test[[&apos;Age&apos;,&apos;Fare&apos;, &apos;Parch&apos;, &apos;SibSp&apos;, &apos;Pclass&apos;]]</span><br><span class="line">null_age = tmp_df[data_test.Age.isnull()].values</span><br><span class="line"></span><br><span class="line"># 根据特征属性X预测年龄并补上</span><br><span class="line">X = null_age[:, 1:]</span><br><span class="line">predictedAges = rfr.predict(X)</span><br><span class="line">data_test.loc[ (data_test.Age.isnull()), &apos;Age&apos; ] = predictedAges</span><br><span class="line"></span><br><span class="line">data_test = set_Cabin_type(data_test)</span><br><span class="line">dummies_Cabin = pd.get_dummies(data_test[&apos;Cabin&apos;], prefix= &apos;Cabin&apos;)</span><br><span class="line">dummies_Embarked = pd.get_dummies(data_test[&apos;Embarked&apos;], prefix= &apos;Embarked&apos;)</span><br><span class="line">dummies_Sex = pd.get_dummies(data_test[&apos;Sex&apos;], prefix= &apos;Sex&apos;)</span><br><span class="line">dummies_Pclass = pd.get_dummies(data_test[&apos;Pclass&apos;], prefix= &apos;Pclass&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df_test = pd.concat([data_test, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)</span><br><span class="line">df_test.drop([&apos;Pclass&apos;, &apos;Name&apos;, &apos;Sex&apos;, &apos;Ticket&apos;, &apos;Cabin&apos;, &apos;Embarked&apos;], axis=1, inplace=True)</span><br><span class="line">df_test[&apos;Age_scaled&apos;] = scaler.fit_transform(df_test[&apos;Age&apos;].values.reshape(-1,1), age_scale_param)</span><br><span class="line">df_test[&apos;Fare_scaled&apos;] = scaler.fit_transform(df_test[&apos;Fare&apos;].values.reshape(-1,1), fare_scale_param)</span><br><span class="line">df_test</span><br></pre></td></tr></table></figure>
<p>预测上传查询得分</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test = df_test.filter(regex=&apos;Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*&apos;)</span><br><span class="line">predictions = clf.predict(test)</span><br><span class="line">result = pd.DataFrame(&#123;&apos;PassengerId&apos;:data_test[&apos;PassengerId&apos;].values, &apos;Survived&apos;:predictions.astype(np.int32)&#125;)</span><br><span class="line">result.to_csv(&quot;logistic_regression_predictions.csv&quot;, index=False)</span><br></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>初始得分0.7655，先结篇后面还需做很多优化处理，朝满分前进！</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:leocheung4ever@gmail.com" target="_blank" rel="noopener">Leo·Cheung</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://tufusi.com/2019/11/25/%E3%80%90Kaggle%E4%B8%93%E6%A0%8F%E3%80%91Titanic%E5%85%A5%E9%97%A8/">http://tufusi.com/2019/11/25/%E3%80%90Kaggle%E4%B8%93%E6%A0%8F%E3%80%91Titanic%E5%85%A5%E9%97%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://tufusi.com">ONE·PIECE</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Kaggle/">Kaggle    </a><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/">数据竞赛    </a><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95/">算法    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/img/alipay.jpg"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/11/30/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E3%80%91%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/niko-photos-tGTVxeOr_Rs-unsplash.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>【机器学习模型】决策树学习（一）</span></div></a></div><div class="next-post pull_right"><a href="/2019/11/24/%E3%80%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%91From-Word-Embeddings-To-Document-Distances/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>【论文笔记】From Word Embeddings To Document Distances</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/11/24/【论文笔记】From-Word-Embeddings-To-Document-Distances/" title="【论文笔记】From Word Embeddings To Document Distances"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/luis-rocha-3UyoEEZBUhQ-unsplash.jpg"><div class="relatedPosts_title">【论文笔记】From Word Embeddings To Document Distances</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="lv-container" data-id="city" data-uid="MTAyMC80NzU5OC8yNDA5OA=="><script>(function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script></div></div></div></div><footer id="footer" style="background-image: url(https://cdn.jsdelivr.net/gh/LeoCheung0221/tufusiCDN@latest/cover/fabio-oyXis2kALVg-unsplash.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2019 By Leo·Cheung</div><div class="footer_custom_text">Some of life, you have to go to the great challanges. - By Kobe Bryant</div><div class="icp"><a href="http://www.beian.miit.gov.cn/state/outPortal/loginPortal.action" target="_blank" rel="noopener"><img class="icp-icon" src="/img/icp.png"><span>浙ICP备19024714号</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script async src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.15/dist/snackbar.min.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/ClickShowText.js"></script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>